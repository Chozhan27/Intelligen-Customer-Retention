# -*- coding: utf-8 -*-
"""Intelligent

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xhg8mrMlS0_dUt8SkhNoS9mi73NTu2T5
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import sklearn
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV 
import imblearn
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,f1_score

data = pd.read_csv(r"/content/Dataset.csv")
data

data.info()

data.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')
data.isnull().any()

data["TotalCharges"].fillna(data["TotalCharges"].median(),inplace=True)

data.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data["gender"] = le.fit_transform(data["gender"])
data["SeniorCitizen"] = le.fit_transform(data["SeniorCitizen"])
data["Partner"] = le.fit_transform(data["Partner"])
data["Dependents"] = le.fit_transform(data["Dependents"])
data["PhoneService"] = le.fit_transform(data["PhoneService"])
data["MultipleLines"] = le.fit_transform(data["MultipleLines"])
data["InternetService"] = le.fit_transform(data["InternetService"])
data["OnlineSecurity"] = le.fit_transform(data["OnlineSecurity"])
data["OnelineBackup"] = le.fit_transform(data["OnlineBackup"])
data["DeviceProtection"] = le.fit_transform(data["DeviceProtection"])
data["TechSupport"] = le.fit_transform(data["TechSupport"])
data["StreamingTV"] = le.fit_transform(data["StreamingTV"])
data["StreamingMovies"] = le.fit_transform(data["StreamingMovies"])
data["Contract"] = le.fit_transform(data["Contract"])
data["PaperlessBilling"] = le.fit_transform(data["PaperlessBilling"])
data["PaymentMethod"] = le.fit_transform(data["PaymentMethod"])
data["Churn"] = le.fit_transform(data["Churn"])

data.head()

x=data.iloc[:,1:20].values
y=data.iloc[:,20:21].values

x

y

from sklearn.preprocessing import OneHotEncoder
one=OneHotEncoder()
a= one.fit_transform(x[:,6:7]).toarray()
b= one.fit_transform(x[:,7:8]).toarray()
c= one.fit_transform(x[:,8:9]).toarray()
d= one.fit_transform(x[:,9:10]).toarray()
e= one.fit_transform(x[:,10:11]).toarray()
f= one.fit_transform(x[:,11:12]).toarray()
g= one.fit_transform(x[:,12:13]).toarray()
h= one.fit_transform(x[:,13:14]).toarray()
i= one.fit_transform(x[:,14:15]).toarray()
j= one.fit_transform(x[:,16:17]).toarray()
x=np.delete(x,[6,7,8,9,10,11,12,13,14,16],axis=1)
x=np.concatenate((a,b,c,d,e,f,g,h,i,j,x),axis=1)

from imblearn.over_sampling import SMOTE

smt=SMOTE()
x_resample,y_resample = smt.fit_resample(x,y)

x_resample

y_resample

x.shape,x_resample.shape

y.shape,y_resample.shape

data.describe()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.distplot(data["tenure"])
plt.subplot(1,2,2)
sns.distplot(data["MonthlyCharges"])

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.countplot(data["gender"])
plt.subplot(1,2,2)
sns.countplot(data["Dependents"])

sns.barplot(x="Churn",y="MonthlyCharges",data=data)

sns.heatmap(data.corr(), annot=True)

sns.pairplot(data=data,markers=["^","v"],palette="inferno")

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x_resample,y_resample,test_size=0.2, random_state=0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

x_train.shape

def logreg(x_train,x_test,y_train,y_test):
  lr = LogisticRegression(random_state=0)
  lr .fit(x_train,y_train)
  y_lr_tr = lr.predict(x_train)
  print(accuracy_score(y_lr_tr,y_train))
  yPred_lr= lr.predict(x_test)
  print(accuracy_score(yPred_lr,y_test))
  print("***Logistic Regression***")
  print("Confusion_Matrix")
  print(confusion_matrix(y_test,yPred_lr))
  print("Classification Report")
  print(classification_report(y_test,yPred_lr))

logreg(x_train,x_test,y_train,y_test)

def decisionTree(x_train,x_test,y_train,y_test):
  dtc = DecisionTreeClassifier(criterion="entropy",random_state=0)
  dtc.fit(x_train,y_train)
  y_dt_tr = dtc.predict(x_train)
  print(accuracy_score(y_dt_tr,y_train))
  yPred_dt = dtc.predict(x_test)
  print(accuracy_score(yPred_dt,y_test))
  print("***Decision Tree***")
  print("***Confusion_Matrix")
  print(confusion_matrix(y_test,yPred_dt))
  print("classifiation Report")
  print(classification_report(y_test,yPred_dt))

decisionTree(x_train,x_test,y_train,y_test)

def RandomForest(x_train,x_test,y_train,y_test):
   rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
   rf.fit(x_train,y_train)
   y_rf_tr = rf.predict(x_train)
   print(accuracy_score(y_rf_tr,y_train))
   yPred_rf = rf.predict(x_test)
   print(accuracy_score(yPred_rf,y_test))
   print("***Random Forest")
   print("Confusion_Matrix")
   print(confusion_matrix(y_test,yPred_rf))
   print("Classification Report")
   print(classification_report(y_test,yPred_rf))

RandomForest(x_train, x_test, y_train, y_test)

def KNN(x_tarin,x_test,y_train,y_test):
   knn = KNeighborsClassifier()
   knn.fit(x_train,y_train)
   y_knn_tr = knn.predict(x_train)
   print(accuracy_score(y_knn_tr,y_train))
   yPred_knn = knn.predict(x_test)
   print(accuracy_score(yPred_knn,y_test))
   print("***KNN***")
   print("Confusion_Matrix")
   print(confusion_matrix(y_test,yPred_knn))
   print("Classification Report")
   print(classification_report(y_test,yPred_knn))

KNN(x_train, x_test, y_train, y_test)

def SVM(x_train,x_test,y_train,y_test):
  SVM = SVC(kernel = "linear")
  SVM.fit(x_train,y_train)
  y_svm_tr = SVM.predict(x_train)
  print(accuracy_score(y_svm_tr,y_train))
  yPred_svm = SVM.predict(x_test)
  print(accuracy_score(yPred_svm,y_test))
  print("***Support Vector Machine***")
  print("Confusion_Matrix")
  print(confusion_matrix(y_test,yPred_svm))
  print("Classification Report")
  print(classification_report(y_test,yPred_svm))

SVM(x_train,x_test,y_train,y_test)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier=Sequential()

classifier.add(Dense(units=30,activation='relu',input_dim=40))

classifier.add(Dense(units=30, activation='relu'))

classifier.add(Dense(units=1,activation='sigmoid'))

classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

model_history = classifier.fit(x_train,y_train, batch_size=10,validation_split=0.33, epochs=200)

ann_pred =classifier.predict(x_test)
ann_pred =(ann_pred>0.5)
ann_pred

print(accuracy_score(ann_pred,y_test))
print("***ANN Model***")
print("confusion_Matrix")
print(confusion_matrix(y_test,ann_pred))
print("classificaion Report")
print(classification_report(y_test,ann_pred))

lr = LogisticRegression(random_state=0)
lr.fit(x_train,y_train)
print("Predicting on random input")
lr_pred_own = lr.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is:", lr_pred_own)

dtc = DecisionTreeClassifier(criterion="entropy",random_state=0)
dtc.fit(x_train,y_train)
print("Predicting on random input")
dtc_pred_own = dtc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3425,4567]]))
print("output is: ",dtc_pred_own)

rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
rf.fit(x_train,y_train)
print("Prediction on random input")
rf_pred_own = rf.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is: ",rf_pred_own)

svc = SVC(kernel = "linear")
svc.fit(x_train,y_train)
print("Prediction on random input")
svm_pred_own = svc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is:",svm_pred_own)

knn = KNeighborsClassifier() 
knn.fit(x_train,y_train)
print("Predicting on random input")
knn_pred_own = knn.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("output is: ",knn_pred_own)

print("Predicting on random input")
classifier.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print(knn_pred_own)
ann_pred_own = (knn_pred_own>0.5)
print("output is: ",knn_pred_own)

def compareModel(x_train,x_test,y_train,y_test):
  logreg(x_train,x_test,y_train,y_test)
  print('-'*100)
  decisionTree(x_train,x_test,y_train,y_test)
  print('-'*100)
  RandomForest(x_train,x_test,y_train,y_test)
  print('-'*100)
  SVM(x_train,x_test,y_train,y_test)
  print('-'*100)
  KNN(x_train,x_test,y_train,y_test)
  print('-'*100)

compareModel(x_train,x_test,y_train,y_test)

print(accuracy_score)
print("***ANN Model***")
print("Confusion_Matrix")
print(confusion_matrix)
print("classification Report")
print(classification_report)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

model = RandomForestClassifier()

params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(model, params, cv=5)
grid_search.fit(x_train, y_train)

print("Best hyperparameters:", grid_search.best_params_)

model = grid_search.best_estimator_

y_rf = model.predict(x_train)
print("Training set accuracy:", accuracy_score(y_rf, y_train))

yPred_rfcv = model.predict(x_test)
print("Test set accuracy:", accuracy_score(yPred_rfcv, y_test))

print("**Random Forest after Hyperparameter tuning**")
print("Confusion Matrix")
print(confusion_matrix(y_test, yPred_rfcv))
print("Classification Report")
print(classification_report(y_test, yPred_rfcv))

rfcv_pred_own = model.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
print("Output is:", rfcv_pred_own)

classifier.save("telcom_churn.h5")

from flask import Flask,render_template,request
import keras
from keras.models import load_model

app = Flask(__name__)
model = load_model("/content/telcom_churn.h5")

@app.route('/')
def home():
    return render_template('home.html')

print("Prediction on random input")
knn_pred_own = classifier.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,10,3245,4567]]))
print(ann_pred_own)
ann_pred_own = (ann_pred_own)
print("output is:",ann_pred_own)

@app.route('/')
def helloworld():
  return render_template("base.html")

@app.route('/assesment')
def prediction():
  return render_template("index.html")

@app.route('/predict',methods=['POST'])
def admin():
  a=request.form["gender"]
  if(a=='f'):
    a=0
  if(a=='m'):
    a=1

if __name__ == "__main__":
    app.run(debug=True)